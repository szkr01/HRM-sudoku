{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "from typing import Tuple, List, Dict, Optional, Any, Sequence, Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.optimizer import Optimizer, ParamsT\n",
    "from torch.optim import AdamW # Using standard AdamW\n",
    "from tqdm import tqdm\n",
    "import coolname\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Model Components\n",
    "# ==============================================================================\n",
    "\n",
    "def trunc_normal_init_(tensor: torch.Tensor, std: float = 1.0, lower: float = -2.0, upper: float = 2.0):\n",
    "    with torch.no_grad():\n",
    "        if std == 0:\n",
    "            tensor.zero_()\n",
    "        else:\n",
    "            sqrt2 = math.sqrt(2)\n",
    "            a = math.erf(lower / sqrt2)\n",
    "            b = math.erf(upper / sqrt2)\n",
    "            z = (b - a) / 2\n",
    "            c = (2 * math.pi) ** -0.5\n",
    "            pdf_u = c * math.exp(-0.5 * lower ** 2)\n",
    "            pdf_l = c * math.exp(-0.5 * upper ** 2)\n",
    "            comp_std = std / math.sqrt(1 - (upper * pdf_u - lower * pdf_l) / z - ((pdf_u - pdf_l) / z) ** 2)\n",
    "            tensor.uniform_(a, b)\n",
    "            tensor.erfinv_()\n",
    "            tensor.mul_(sqrt2 * comp_std)\n",
    "            tensor.clip_(lower * comp_std, upper * comp_std)\n",
    "    return tensor\n",
    "\n",
    "CosSin = Tuple[torch.Tensor, torch.Tensor]\n",
    "\n",
    "def _find_multiple(a, b):\n",
    "    return (-(a // -b)) * b\n",
    "\n",
    "def rotate_half(x: torch.Tensor):\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q: torch.Tensor, k: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor):\n",
    "    orig_dtype = q.dtype\n",
    "    q = q.to(cos.dtype)\n",
    "    k = k.to(cos.dtype)\n",
    "    q_embed = (q * cos.unsqueeze(-2)) + (rotate_half(q) * sin.unsqueeze(-2))\n",
    "    k_embed = (k * cos.unsqueeze(-2)) + (rotate_half(k) * sin.unsqueeze(-2))\n",
    "    return q_embed.to(orig_dtype), k_embed.to(orig_dtype)\n",
    "\n",
    "class CastedLinear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(trunc_normal_init_(torch.empty((out_features, in_features)), std=1.0 / (in_features ** 0.5)))\n",
    "        self.bias = nn.Parameter(torch.zeros((out_features, ))) if bias else None\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        bias = self.bias.to(input.dtype) if self.bias is not None else None\n",
    "        return F.linear(input, self.weight.to(input.dtype), bias=bias)\n",
    "\n",
    "class CastedEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, init_std: float, cast_to: torch.dtype):\n",
    "        super().__init__()\n",
    "        self.cast_to = cast_to\n",
    "        self.embedding_weight = nn.Parameter(trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std))\n",
    "        \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return F.embedding(input, self.embedding_weight.to(self.cast_to))\n",
    "\n",
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings, base, device=None):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.float32, device=device) / dim))\n",
    "        t = torch.arange(max_position_embeddings, dtype=torch.float32, device=device)\n",
    "        freqs = torch.outer(t, inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos(), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin(), persistent=False)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.cos_cached, self.sin_cached\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, head_dim, num_heads, num_key_value_heads, causal=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.head_dim = head_dim\n",
    "        self.output_size = head_dim * num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        self.causal = causal\n",
    "        self.qkv_proj = CastedLinear(self.hidden_size, (self.num_heads + 2 * self.num_key_value_heads) * self.head_dim, bias=False)\n",
    "        self.o_proj = CastedLinear(self.output_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, cos_sin: Optional[CosSin], hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len, _ = hidden_states.shape\n",
    "        qkv = self.qkv_proj(hidden_states)\n",
    "        qkv = qkv.view(batch_size, seq_len, self.num_heads + 2 * self.num_key_value_heads, self.head_dim)\n",
    "        query = qkv[:, :, :self.num_heads]\n",
    "        key = qkv[:, :, self.num_heads: self.num_heads + self.num_key_value_heads]\n",
    "        value = qkv[:, :, self.num_heads + self.num_key_value_heads:]\n",
    "\n",
    "        if cos_sin is not None:\n",
    "            cos, sin = cos_sin\n",
    "            query, key = apply_rotary_pos_emb(query, key, cos, sin)\n",
    "        \n",
    "        # Using PyTorch's native scaled_dot_product_attention instead of flash-attn\n",
    "        # It expects shape (batch, heads, seq_len, dim)\n",
    "        query = query.transpose(1, 2)\n",
    "        key = key.transpose(1, 2)\n",
    "        value = value.transpose(1, 2)\n",
    "        \n",
    "        attn_output = F.scaled_dot_product_attention(query, key, value, is_causal=self.causal)\n",
    "        \n",
    "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "        attn_output = attn_output.view(batch_size, seq_len, self.output_size)\n",
    "        return self.o_proj(attn_output)\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, hidden_size: int, expansion: float):\n",
    "        super().__init__()\n",
    "        inter = _find_multiple(round(expansion * hidden_size * 2 / 3), 256)\n",
    "        self.gate_up_proj = CastedLinear(hidden_size, inter * 2, bias=False)\n",
    "        self.down_proj = CastedLinear(inter, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate, up = self.gate_up_proj(x).chunk(2, dim=-1)\n",
    "        return self.down_proj(F.silu(gate) * up)\n",
    "\n",
    "def rms_norm(hidden_states: torch.Tensor, variance_epsilon: float) -> torch.Tensor:\n",
    "    input_dtype = hidden_states.dtype\n",
    "    hidden_states = hidden_states.to(torch.float32)\n",
    "    variance = hidden_states.square().mean(-1, keepdim=True)\n",
    "    hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
    "    return hidden_states.to(input_dtype)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Sparse Embedding\n",
    "# ==============================================================================\n",
    "\n",
    "class CastedSparseEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, batch_size: int, init_std: float, cast_to: torch.dtype):\n",
    "        super().__init__()\n",
    "        self.cast_to = cast_to\n",
    "        self.register_buffer('weights', trunc_normal_init_(torch.empty((num_embeddings, embedding_dim)), std=init_std))\n",
    "        self.register_buffer('local_weights', torch.zeros(batch_size, embedding_dim, requires_grad=True), persistent=False)\n",
    "        self.register_buffer('local_ids', torch.zeros(batch_size, dtype=torch.int32), persistent=False)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        if not self.training:\n",
    "            return self.weights[inputs].to(self.cast_to)\n",
    "        with torch.no_grad():\n",
    "            self.local_weights.copy_(self.weights[inputs])\n",
    "            self.local_ids.copy_(inputs)\n",
    "        return self.local_weights.to(self.cast_to)\n",
    "\n",
    "class CastedSparseEmbeddingSignSGD(Optimizer):\n",
    "    def __init__(self, params: ParamsT, lr: float = 1e-3, weight_decay: float = 1e-2):\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            local_weights_grad, local_ids, weights = None, None, None\n",
    "            for p in group[\"params\"]:\n",
    "                if p.requires_grad: local_weights_grad = p.grad\n",
    "                elif p.ndim == 1: local_ids = p\n",
    "                elif p.ndim == 2: weights = p\n",
    "            \n",
    "            if local_weights_grad is None or local_ids is None or weights is None: continue\n",
    "\n",
    "            grad_ids, inv = local_ids.unique(return_inverse=True)\n",
    "            grad = torch.zeros((grad_ids.shape[0], local_weights_grad.shape[1]), dtype=local_weights_grad.dtype, device=local_weights_grad.device)\n",
    "            grad.scatter_add_(0, inv.unsqueeze(-1).expand(-1, local_weights_grad.shape[1]), local_weights_grad)\n",
    "            \n",
    "            p = weights[grad_ids]\n",
    "            p.mul_(1.0 - group['lr'] * group['weight_decay']).add_(torch.sign(grad), alpha=-group['lr'])\n",
    "            weights[grad_ids] = p\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Main Model\n",
    "# ==============================================================================\n",
    "\n",
    "@dataclass\n",
    "class HierarchicalReasoningModel_ACTV1InnerCarry:\n",
    "    z_H: torch.Tensor\n",
    "    z_L: torch.Tensor\n",
    "\n",
    "@dataclass\n",
    "class HierarchicalReasoningModel_ACTV1Carry:\n",
    "    inner_carry: HierarchicalReasoningModel_ACTV1InnerCarry\n",
    "    steps: torch.Tensor\n",
    "    halted: torch.Tensor\n",
    "    current_data: Dict[str, torch.Tensor]\n",
    "\n",
    "class HierarchicalReasoningModel_ACTV1Config(BaseModel):\n",
    "    batch_size: int\n",
    "    seq_len: int\n",
    "    puzzle_emb_ndim: int\n",
    "    num_puzzle_identifiers: int\n",
    "    vocab_size: int\n",
    "    H_cycles: int\n",
    "    L_cycles: int\n",
    "    H_layers: int\n",
    "    L_layers: int\n",
    "    hidden_size: int\n",
    "    expansion: float\n",
    "    num_heads: int\n",
    "    pos_encodings: str\n",
    "    rms_norm_eps: float = 1e-5\n",
    "    rope_theta: float = 10000.0\n",
    "    halt_max_steps: int\n",
    "    halt_exploration_prob: float\n",
    "    forward_dtype: str = \"bfloat16\" if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else \"float32\"\n",
    "\n",
    "class HierarchicalReasoningModel_ACTV1Block(nn.Module):\n",
    "    def __init__(self, config: HierarchicalReasoningModel_ACTV1Config) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attn = Attention(\n",
    "            hidden_size=config.hidden_size,\n",
    "            head_dim=config.hidden_size // config.num_heads,\n",
    "            num_heads=config.num_heads,\n",
    "            num_key_value_heads=config.num_heads,\n",
    "            causal=False\n",
    "        )\n",
    "        self.mlp = SwiGLU(hidden_size=config.hidden_size, expansion=config.expansion)\n",
    "        self.norm_eps = config.rms_norm_eps\n",
    "\n",
    "    def forward(self, cos_sin: Optional[CosSin], hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = rms_norm(hidden_states + self.self_attn(cos_sin=cos_sin, hidden_states=hidden_states), variance_epsilon=self.norm_eps)\n",
    "        hidden_states = rms_norm(hidden_states + self.mlp(hidden_states), variance_epsilon=self.norm_eps)\n",
    "        return hidden_states\n",
    "\n",
    "class HierarchicalReasoningModel_ACTV1ReasoningModule(nn.Module):\n",
    "    def __init__(self, layers: List[HierarchicalReasoningModel_ACTV1Block]):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_injection: torch.Tensor, **kwargs) -> torch.Tensor:\n",
    "        hidden_states = hidden_states + input_injection\n",
    "        for layer in self.layers:\n",
    "            hidden_states = layer(hidden_states=hidden_states, **kwargs)\n",
    "        return hidden_states\n",
    "\n",
    "class HierarchicalReasoningModel_ACTV1_Inner(nn.Module):\n",
    "    def __init__(self, config: HierarchicalReasoningModel_ACTV1Config) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.forward_dtype = getattr(torch, self.config.forward_dtype)\n",
    "        self.embed_scale = math.sqrt(self.config.hidden_size)\n",
    "        embed_init_std = 1.0 / self.embed_scale\n",
    "        self.embed_tokens = CastedEmbedding(self.config.vocab_size, self.config.hidden_size, init_std=embed_init_std, cast_to=self.forward_dtype)\n",
    "        self.lm_head = CastedLinear(self.config.hidden_size, self.config.vocab_size, bias=False)\n",
    "        self.q_head = CastedLinear(self.config.hidden_size, 2, bias=True)\n",
    "        self.puzzle_emb_len = -(self.config.puzzle_emb_ndim // -self.config.hidden_size)\n",
    "        \n",
    "        if self.config.puzzle_emb_ndim > 0:\n",
    "            self.puzzle_emb = CastedSparseEmbedding(self.config.num_puzzle_identifiers, self.config.puzzle_emb_ndim, batch_size=self.config.batch_size, init_std=0, cast_to=self.forward_dtype)\n",
    "\n",
    "        if self.config.pos_encodings == \"rope\":\n",
    "            self.rotary_emb = RotaryEmbedding(dim=self.config.hidden_size // self.config.num_heads, max_position_embeddings=self.config.seq_len + self.puzzle_emb_len, base=self.config.rope_theta)\n",
    "        elif self.config.pos_encodings == \"learned\":\n",
    "            self.embed_pos = CastedEmbedding(self.config.seq_len + self.puzzle_emb_len, self.config.hidden_size, init_std=embed_init_std, cast_to=self.forward_dtype)\n",
    "        \n",
    "        self.H_level = HierarchicalReasoningModel_ACTV1ReasoningModule(layers=[HierarchicalReasoningModel_ACTV1Block(self.config) for _ in range(self.config.H_layers)])\n",
    "        self.L_level = HierarchicalReasoningModel_ACTV1ReasoningModule(layers=[HierarchicalReasoningModel_ACTV1Block(self.config) for _ in range(self.config.L_layers)])\n",
    "        \n",
    "        self.register_buffer('H_init', trunc_normal_init_(torch.empty(self.config.hidden_size, dtype=self.forward_dtype), std=1))\n",
    "        self.register_buffer('L_init', trunc_normal_init_(torch.empty(self.config.hidden_size, dtype=self.forward_dtype), std=1))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.q_head.weight.zero_()\n",
    "            if self.q_head.bias is not None:\n",
    "                self.q_head.bias.fill_(-5)\n",
    "\n",
    "    def _input_embeddings(self, input_tensor: torch.Tensor, puzzle_identifiers: torch.Tensor):\n",
    "        embedding = self.embed_tokens(input_tensor.to(torch.int32))\n",
    "        if self.config.puzzle_emb_ndim > 0 and hasattr(self, 'puzzle_emb'):\n",
    "            puzzle_embedding = self.puzzle_emb(puzzle_identifiers)\n",
    "            pad_count = self.puzzle_emb_len * self.config.hidden_size - puzzle_embedding.shape[-1]\n",
    "            if pad_count > 0:\n",
    "                puzzle_embedding = F.pad(puzzle_embedding, (0, pad_count))\n",
    "            embedding = torch.cat((puzzle_embedding.view(-1, self.puzzle_emb_len, self.config.hidden_size), embedding), dim=-2)\n",
    "        if self.config.pos_encodings == \"learned\":\n",
    "            embedding = 0.707106781 * (embedding + self.embed_pos.embedding_weight.to(self.forward_dtype))\n",
    "        return self.embed_scale * embedding\n",
    "\n",
    "    def empty_carry(self, batch_size: int):\n",
    "        device = self.H_init.device\n",
    "        return HierarchicalReasoningModel_ACTV1InnerCarry(\n",
    "            z_H=torch.empty(batch_size, self.config.seq_len + self.puzzle_emb_len, self.config.hidden_size, dtype=self.forward_dtype, device=device),\n",
    "            z_L=torch.empty(batch_size, self.config.seq_len + self.puzzle_emb_len, self.config.hidden_size, dtype=self.forward_dtype, device=device),\n",
    "        )\n",
    "        \n",
    "    def reset_carry(self, reset_flag: torch.Tensor, carry: HierarchicalReasoningModel_ACTV1InnerCarry):\n",
    "        return HierarchicalReasoningModel_ACTV1InnerCarry(\n",
    "            z_H=torch.where(reset_flag.view(-1, 1, 1), self.H_init, carry.z_H),\n",
    "            z_L=torch.where(reset_flag.view(-1, 1, 1), self.L_init, carry.z_L),\n",
    "        )\n",
    "\n",
    "    def forward(self, carry: HierarchicalReasoningModel_ACTV1InnerCarry, batch: Dict[str, torch.Tensor]) -> Tuple[HierarchicalReasoningModel_ACTV1InnerCarry, torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        seq_info = dict(cos_sin=self.rotary_emb() if hasattr(self, \"rotary_emb\") else None)\n",
    "        input_embeddings = self._input_embeddings(batch[\"inputs\"], batch[\"puzzle_identifiers\"])\n",
    "        z_H, z_L = carry.z_H, carry.z_L\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(self.config.H_cycles):\n",
    "                for _ in range(self.config.L_cycles -1):\n",
    "                    z_L = self.L_level(z_L, z_H + input_embeddings, **seq_info)\n",
    "                z_L = self.L_level(z_L, z_H + input_embeddings, **seq_info) # last L_cycle for H\n",
    "                z_H = self.H_level(z_H, z_L, **seq_info)\n",
    "\n",
    "        z_L = self.L_level(z_L.detach(), z_H.detach() + input_embeddings, **seq_info)\n",
    "        z_H = self.H_level(z_H.detach(), z_L, **seq_info)\n",
    "\n",
    "        new_carry = HierarchicalReasoningModel_ACTV1InnerCarry(z_H=z_H.detach(), z_L=z_L.detach())\n",
    "        output = self.lm_head(z_H)[:, self.puzzle_emb_len:]\n",
    "        q_logits = self.q_head(z_H[:, 0]).to(torch.float32)\n",
    "        return new_carry, output, (q_logits[..., 0], q_logits[..., 1])\n",
    "\n",
    "class HierarchicalReasoningModel_ACTV1(nn.Module):\n",
    "    def __init__(self, config_dict: dict):\n",
    "        super().__init__()\n",
    "        self.config = HierarchicalReasoningModel_ACTV1Config(**config_dict)\n",
    "        self.inner = HierarchicalReasoningModel_ACTV1_Inner(self.config)\n",
    "\n",
    "    @property\n",
    "    def puzzle_emb(self):\n",
    "        return self.inner.puzzle_emb\n",
    "\n",
    "    def initial_carry(self, batch: Dict[str, torch.Tensor]):\n",
    "        batch_size = batch[\"inputs\"].shape[0]\n",
    "        device = batch[\"inputs\"].device\n",
    "        return HierarchicalReasoningModel_ACTV1Carry(\n",
    "            inner_carry=self.inner.empty_carry(batch_size),\n",
    "            steps=torch.zeros((batch_size,), dtype=torch.int32, device=device),\n",
    "            halted=torch.ones((batch_size,), dtype=torch.bool, device=device),\n",
    "            current_data={k: torch.empty_like(v) for k, v in batch.items()}\n",
    "        )\n",
    "        \n",
    "    def forward(self, carry: HierarchicalReasoningModel_ACTV1Carry, batch: Dict[str, torch.Tensor]) -> Tuple[HierarchicalReasoningModel_ACTV1Carry, Dict[str, torch.Tensor]]:\n",
    "        new_inner_carry = self.inner.reset_carry(carry.halted, carry.inner_carry)\n",
    "        new_steps = torch.where(carry.halted, 0, carry.steps)\n",
    "        new_current_data = {k: torch.where(carry.halted.view((-1,) + (1,) * (batch[k].ndim - 1)), batch[k], v) for k, v in carry.current_data.items()}\n",
    "        \n",
    "        new_inner_carry, logits, (q_halt_logits, q_continue_logits) = self.inner(new_inner_carry, new_current_data)\n",
    "        outputs = {\"logits\": logits, \"q_halt_logits\": q_halt_logits, \"q_continue_logits\": q_continue_logits}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            new_steps += 1\n",
    "            is_last_step = new_steps >= self.config.halt_max_steps\n",
    "            halted = is_last_step\n",
    "            if self.training and (self.config.halt_max_steps > 1):\n",
    "                halted = halted | (q_halt_logits > q_continue_logits)\n",
    "                min_halt_steps = (torch.rand_like(q_halt_logits) < self.config.halt_exploration_prob) * torch.randint_like(new_steps, low=2, high=self.config.halt_max_steps + 1)\n",
    "                halted = halted & (new_steps >= min_halt_steps)\n",
    "                next_q_halt_logits, next_q_continue_logits = self.inner(new_inner_carry, new_current_data)[-1]\n",
    "                outputs[\"target_q_continue\"] = torch.sigmoid(torch.where(is_last_step, next_q_halt_logits, torch.maximum(next_q_halt_logits, next_q_continue_logits)))\n",
    "        \n",
    "        return HierarchicalReasoningModel_ACTV1Carry(new_inner_carry, new_steps, halted, new_current_data), outputs\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. Loss Head\n",
    "# ==============================================================================\n",
    "IGNORE_LABEL_ID = -100\n",
    "\n",
    "def s(x, epsilon=1e-30):\n",
    "    return torch.where(x < 0, 1 / (1 - x + epsilon), x + 1)\n",
    "\n",
    "def log_stablemax(x, dim=-1):\n",
    "    s_x = s(x)\n",
    "    return torch.log(s_x / torch.sum(s_x, dim=dim, keepdim=True))\n",
    "\n",
    "def stablemax_cross_entropy(logits, labels, ignore_index: int = -100):\n",
    "    logprobs = log_stablemax(logits.to(torch.float64), dim=-1)\n",
    "    valid_mask = labels != ignore_index\n",
    "    transformed_labels = torch.where(valid_mask, labels, 0)\n",
    "    prediction_logprobs = torch.gather(logprobs, index=transformed_labels.to(torch.long).unsqueeze(-1), dim=-1).squeeze(-1)\n",
    "    return -torch.where(valid_mask, prediction_logprobs, 0)\n",
    "\n",
    "def softmax_cross_entropy(logits, labels, ignore_index: int = -100):\n",
    "    return F.cross_entropy(logits.to(torch.float32).flatten(0, 1), labels.to(torch.long).flatten(), ignore_index=ignore_index, reduction=\"none\").view(labels.shape)\n",
    "\n",
    "class ACTLossHead(nn.Module):\n",
    "    def __init__(self, model: nn.Module, loss_type: str):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_fn = globals()[loss_type]\n",
    "        \n",
    "    def initial_carry(self, *args, **kwargs):\n",
    "        return self.model.initial_carry(*args, **kwargs)\n",
    "\n",
    "    def forward(self, carry: Any, batch: Dict[str, torch.Tensor], return_keys: Sequence[str] = ()):\n",
    "        new_carry, outputs = self.model(carry, batch)\n",
    "        labels = new_carry.current_data[\"labels\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mask = labels != IGNORE_LABEL_ID\n",
    "            loss_counts = mask.sum(-1)\n",
    "            loss_divisor = loss_counts.clamp_min(1)\n",
    "            is_correct = mask & (torch.argmax(outputs[\"logits\"], dim=-1) == labels)\n",
    "            seq_is_correct = is_correct.sum(-1) == loss_counts\n",
    "            valid_metrics = new_carry.halted & (loss_counts > 0)\n",
    "            metrics = {\n",
    "                \"count\": valid_metrics.sum(),\n",
    "                \"accuracy\": torch.where(valid_metrics, is_correct.float().sum(-1) / loss_divisor, 0).sum(),\n",
    "                \"exact_accuracy\": (valid_metrics & seq_is_correct).sum(),\n",
    "                \"q_halt_accuracy\": (valid_metrics & ((outputs[\"q_halt_logits\"] >= 0) == seq_is_correct)).sum(),\n",
    "                \"steps\": torch.where(valid_metrics, new_carry.steps, 0).sum(),\n",
    "            }\n",
    "\n",
    "        lm_loss = (self.loss_fn(outputs[\"logits\"], labels, ignore_index=IGNORE_LABEL_ID).sum(-1) / loss_divisor).sum()\n",
    "        q_halt_loss = F.binary_cross_entropy_with_logits(outputs[\"q_halt_logits\"], seq_is_correct.to(outputs[\"q_halt_logits\"].dtype), reduction=\"sum\")\n",
    "        metrics.update({\"lm_loss\": lm_loss.detach(), \"q_halt_loss\": q_halt_loss.detach()})\n",
    "\n",
    "        q_continue_loss = torch.tensor(0.0, device=lm_loss.device)\n",
    "        if \"target_q_continue\" in outputs:\n",
    "            q_continue_loss = F.binary_cross_entropy_with_logits(outputs[\"q_continue_logits\"], outputs[\"target_q_continue\"], reduction=\"sum\")\n",
    "            metrics[\"q_continue_loss\"] = q_continue_loss.detach()\n",
    "\n",
    "        total_loss = lm_loss + 0.5 * (q_halt_loss + q_continue_loss)\n",
    "        detached_outputs = {k: outputs[k].detach() for k in return_keys if k in outputs}\n",
    "        return new_carry, total_loss, metrics, detached_outputs, new_carry.halted.all()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. Sudoku Dataset\n",
    "# ==============================================================================\n",
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self, puzzles, solutions):\n",
    "        self.puzzles = puzzles\n",
    "        self.solutions = solutions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.puzzles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Flatten and convert to long tensor\n",
    "        # Original data: 0 for blank, 1-9 for digits.\n",
    "        # Model expects vocab: 0 for PAD, 1 for blank, 2-10 for digits 1-9.\n",
    "        # So, we add 1 to all values.\n",
    "        puzzle = torch.from_numpy(self.puzzles[idx].flatten().astype(np.int64)) + 1\n",
    "        solution = torch.from_numpy(self.solutions[idx].flatten().astype(np.int64)) + 1\n",
    "        return {\"inputs\": puzzle, \"labels\": solution}\n",
    "\n",
    "# ==============================================================================\n",
    "# 7. Main Training & Evaluation Loop\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    cfg = Config()\n",
    "    torch.manual_seed(cfg.seed)\n",
    "    np.random.seed(cfg.seed)\n",
    "    \n",
    "    # --- 1. Setup ---\n",
    "    writer = SummaryWriter(f'runs/{cfg.run_name}')\n",
    "    os.makedirs(cfg.checkpoint_path, exist_ok=True)\n",
    "    \n",
    "    print(\"===================================================\")\n",
    "    print(f\"Starting run: {cfg.run_name}\")\n",
    "    print(f\"Device: {cfg.device}\")\n",
    "    print(f\"Configuration: {cfg}\")\n",
    "    print(\"===================================================\")\n",
    "\n",
    "    # --- 2. Data Loading ---\n",
    "    with np.load(cfg.data_path) as data:\n",
    "        puzzles = data['puzzles']\n",
    "        solutions = data['solutions']\n",
    "    \n",
    "    # Shuffle data before splitting\n",
    "    indices = np.arange(len(puzzles))\n",
    "    np.random.shuffle(indices)\n",
    "    puzzles = puzzles[indices]\n",
    "    solutions = solutions[indices]\n",
    "\n",
    "    train_puzzles, val_puzzles = puzzles[:cfg.num_train_samples], puzzles[cfg.num_train_samples:]\n",
    "    train_solutions, val_solutions = solutions[:cfg.num_train_samples], solutions[cfg.num_train_samples:]\n",
    "    \n",
    "    train_dataset = SudokuDataset(train_puzzles, train_solutions)\n",
    "    val_dataset = SudokuDataset(val_puzzles, val_solutions)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.global_batch_size, shuffle=True, num_workers=0,drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=0,drop_last=True)\n",
    "    \n",
    "    # --- 3. Model & Optimizer ---\n",
    "    model_cfg_dict = {\n",
    "        \"batch_size\": cfg.global_batch_size,\n",
    "        \"seq_len\": 81,\n",
    "        \"puzzle_emb_ndim\": cfg.puzzle_emb_ndim,\n",
    "        \"num_puzzle_identifiers\": 1, # Only one task: Sudoku\n",
    "        \"vocab_size\": 11, # 0=PAD, 1=blank, 2-10 for digits 1-9\n",
    "        \"H_cycles\": cfg.H_cycles,\n",
    "        \"L_cycles\": cfg.L_cycles,\n",
    "        \"H_layers\": cfg.H_layers,\n",
    "        \"L_layers\": cfg.L_layers,\n",
    "        \"hidden_size\": cfg.hidden_size,\n",
    "        \"expansion\": cfg.expansion,\n",
    "        \"num_heads\": cfg.num_heads,\n",
    "        \"pos_encodings\": cfg.pos_encodings,\n",
    "        \"halt_max_steps\": cfg.halt_max_steps,\n",
    "        \"halt_exploration_prob\": cfg.halt_exploration_prob,\n",
    "    }\n",
    "    \n",
    "    base_model = HierarchicalReasoningModel_ACTV1(model_cfg_dict).to(cfg.device)\n",
    "    model = ACTLossHead(base_model, loss_type=cfg.loss_type).to(cfg.device)\n",
    "\n",
    "    # For Sudoku, sparse embedding optimizer is not really needed as there's only one puzzle type.\n",
    "    # We use a standard optimizer for all parameters.\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.lr,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "        betas=(cfg.beta1, cfg.beta2)\n",
    "    )\n",
    "\n",
    "    total_steps = len(train_loader) * cfg.epochs\n",
    "    \n",
    "    # --- 4. Training Loop ---\n",
    "    global_step = 0\n",
    "    train_carry = None\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.epochs}\")\n",
    "        for batch in pbar:\n",
    "            batch = {k: v.to(cfg.device) for k, v in batch.items()}\n",
    "            # Sudoku is a single task, so puzzle_identifiers are all zeros\n",
    "            batch[\"puzzle_identifiers\"] = torch.zeros(batch[\"inputs\"].shape[0], dtype=torch.long, device=cfg.device)\n",
    "\n",
    "            if train_carry is None:\n",
    "                train_carry = model.initial_carry(batch)\n",
    "\n",
    "            # Update learning rate\n",
    "            lr = cfg.lr\n",
    "            if global_step < cfg.lr_warmup_steps:\n",
    "                lr = cfg.lr * (global_step / cfg.lr_warmup_steps)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_carry, loss, metrics, _, _ = model(carry=train_carry, batch=batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Logging\n",
    "            count = metrics['count'].item()\n",
    "            if count > 0:\n",
    "                for k, v in metrics.items():\n",
    "                    if k != 'count':\n",
    "                        writer.add_scalar(f\"train/{k}\", v.item() / count, global_step)\n",
    "                writer.add_scalar(\"train/loss\", loss.item() / count, global_step)\n",
    "                writer.add_scalar(\"train/learning_rate\", lr, global_step)\n",
    "            \n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            global_step += 1\n",
    "            \n",
    "        # --- 5. Evaluation ---\n",
    "        if (epoch + 1) % cfg.eval_interval == 0:\n",
    "            model.eval()\n",
    "            val_metrics = {}\n",
    "            with torch.no_grad():\n",
    "                val_carry = None\n",
    "                for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "                    batch = {k: v.to(cfg.device) for k, v in batch.items()}\n",
    "                    batch[\"puzzle_identifiers\"] = torch.zeros(batch[\"inputs\"].shape[0], dtype=torch.long, device=cfg.device)\n",
    "\n",
    "                    if val_carry is None:\n",
    "                         val_carry = model.initial_carry(batch)\n",
    "\n",
    "                    while True:\n",
    "                        val_carry, _, metrics, _, all_finished = model(carry=val_carry, batch=batch)\n",
    "                        for k, v in metrics.items():\n",
    "                            val_metrics[k] = val_metrics.get(k, 0) + v.item()\n",
    "                        if all_finished:\n",
    "                            break\n",
    "            \n",
    "            # Log validation metrics\n",
    "            count = val_metrics.pop('count')\n",
    "            if count > 0:\n",
    "                print(f\"\\n--- Validation Results (Epoch {epoch+1}) ---\")\n",
    "                for k, v in val_metrics.items():\n",
    "                    avg_v = v / count\n",
    "                    writer.add_scalar(f\"val/{k}\", avg_v, global_step)\n",
    "                    print(f\"  {k}: {avg_v:.4f}\")\n",
    "                print(\"----------------------------------------\")\n",
    "                if val_metrics.get('exact_accuracy', 0) / count >= 1.0:\n",
    "                    print(\"Early stopping as exact accuracy reached 100%\")\n",
    "                    # Save the best model\n",
    "                    best_model_file = os.path.join(cfg.checkpoint_path, \"best_model.pt\")\n",
    "                    torch.save(model.state_dict(), best_model_file)\n",
    "                    print(f\"Best model saved to {best_model_file}\")\n",
    "                    break\n",
    "        \n",
    "    # Save checkpoint\n",
    "    checkpoint_file = os.path.join(cfg.checkpoint_path, f\"epoch_{epoch+1}.pt\")\n",
    "    torch.save(model.state_dict(), checkpoint_file)\n",
    "    print(f\"Checkpoint saved to {checkpoint_file}\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b891183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. Configuration\n",
    "# ==============================================================================\n",
    "class Config:\n",
    "    # Data\n",
    "    data_path: str = \"sudoku_dataset_2100.npz\"\n",
    "    num_train_samples: int = 2000\n",
    "    num_val_samples: int = 100\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    global_batch_size: int = 1000\n",
    "    epochs: int = 2000 # Reduced for faster demonstration\n",
    "    eval_interval: int = 5 # Evaluate every 5 epochs\n",
    "    \n",
    "    lr: float = 7e-5\n",
    "    lr_min_ratio: float = 1.0\n",
    "    lr_warmup_steps: int = 100\n",
    "    \n",
    "    weight_decay: float = 1.0\n",
    "    beta1: float = 0.9\n",
    "    beta2: float = 0.95\n",
    "    \n",
    "    # Puzzle embedding (not used for Sudoku but kept for compatibility)\n",
    "    puzzle_emb_lr: float = 7e-5\n",
    "    puzzle_emb_weight_decay: float = 1.0\n",
    "\n",
    "    # Model Architecture (from hrm_v1.yaml)\n",
    "    halt_exploration_prob: float = 0.1\n",
    "    halt_max_steps: int = 8\n",
    "    H_cycles: int = 2\n",
    "    L_cycles: int = 2\n",
    "    H_layers: int = 4\n",
    "    L_layers: int = 4\n",
    "    hidden_size: int = 384\n",
    "    num_heads: int = 8\n",
    "    expansion: int = 4\n",
    "    puzzle_emb_ndim: int = 384\n",
    "    pos_encodings: str = \"rope\" # 'rope' or 'learned'\n",
    "    \n",
    "    # Loss\n",
    "    loss_type: str = \"softmax_cross_entropy\" # 'softmax_cross_entropy' or 'stablemax_cross_entropy'\n",
    "\n",
    "    # System\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Logging\n",
    "    run_name: str = f\"sudoku_{coolname.generate_slug(2)}\"\n",
    "    checkpoint_path: str = f\"checkpoints/{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb2c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "model_cfg_dict = {\n",
    "        \"batch_size\": cfg.global_batch_size,\n",
    "        \"seq_len\": 81,\n",
    "        \"puzzle_emb_ndim\": cfg.puzzle_emb_ndim,\n",
    "        \"num_puzzle_identifiers\": 1, # Only one task: Sudoku\n",
    "        \"vocab_size\": 11, # 0=PAD, 1=blank, 2-10 for digits 1-9\n",
    "        \"H_cycles\": cfg.H_cycles,\n",
    "        \"L_cycles\": cfg.L_cycles,\n",
    "        \"H_layers\": cfg.H_layers,\n",
    "        \"L_layers\": cfg.L_layers,\n",
    "        \"hidden_size\": cfg.hidden_size,\n",
    "        \"expansion\": cfg.expansion,\n",
    "        \"num_heads\": cfg.num_heads,\n",
    "        \"pos_encodings\": cfg.pos_encodings,\n",
    "        \"halt_max_steps\": cfg.halt_max_steps,\n",
    "        \"halt_exploration_prob\": cfg.halt_exploration_prob,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60619a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = HierarchicalReasoningModel_ACTV1(model_cfg_dict).to(cfg.device)\n",
    "model = ACTLossHead(base_model, loss_type=cfg.loss_type).to(cfg.device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/sudoku_adaptable-leech/epoch_500.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "\n",
    "class InferenceModel(nn.Module):\n",
    "    def __init__(self, inner_model: HierarchicalReasoningModel_ACTV1_Inner):\n",
    "        super().__init__()\n",
    "        self.inner = inner_model\n",
    "\n",
    "    def forward(self, \n",
    "                inputs: torch.Tensor, \n",
    "                puzzle_identifiers: torch.Tensor,\n",
    "                z_H_in: torch.Tensor, \n",
    "                z_L_in: torch.Tensor\n",
    "               ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        carry = HierarchicalReasoningModel_ACTV1InnerCarry(z_H=z_H_in, z_L=z_L_in)\n",
    "        batch = { \"inputs\": inputs, \"puzzle_identifiers\": puzzle_identifiers }\n",
    "        new_carry, logits, (q_halt, q_continue) = self.inner(carry, batch)\n",
    "        \n",
    "        return logits, new_carry.z_H, new_carry.z_L\n",
    "\n",
    "def export_to_onnx():\n",
    "    cfg = Config()\n",
    "    batch_size = 1\n",
    "    cfg.device = 'cpu'\n",
    "    CHECKPOINT_PATH = f\"./checkpoints/sudoku_able-junglefowl/epoch_500.pt\"\n",
    "    ONNX_MODEL_PATH = \"sudoku_hrm_inner_fp16.onnx\"\n",
    "\n",
    "    print(f\"Loading checkpoint from: {CHECKPOINT_PATH}\")\n",
    "\n",
    "    model_cfg_dict = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"seq_len\": 81,\n",
    "        \"puzzle_emb_ndim\": cfg.puzzle_emb_ndim,\n",
    "        \"num_puzzle_identifiers\": 1,\n",
    "        \"vocab_size\": 11,\n",
    "        \"H_cycles\": cfg.H_cycles,\n",
    "        \"L_cycles\": cfg.L_cycles,\n",
    "        \"H_layers\": cfg.H_layers,\n",
    "        \"L_layers\": cfg.L_layers,\n",
    "        \"hidden_size\": cfg.hidden_size,\n",
    "        \"expansion\": cfg.expansion,\n",
    "        \"num_heads\": cfg.num_heads,\n",
    "        \"pos_encodings\": cfg.pos_encodings,\n",
    "        \"halt_max_steps\": cfg.halt_max_steps,\n",
    "        \"halt_exploration_prob\": cfg.halt_exploration_prob,\n",
    "        \"forward_dtype\": \"float16\",\n",
    "    }\n",
    "\n",
    "    inner_model = HierarchicalReasoningModel_ACTV1(model_cfg_dict).inner.to(cfg.device)\n",
    "    \n",
    "    state_dict = torch.load(CHECKPOINT_PATH, map_location=cfg.device)\n",
    "    inner_state_dict = {\n",
    "        k.replace('model.inner.', ''): v \n",
    "        for k, v in state_dict.items() \n",
    "        if k.startswith('model.inner.')\n",
    "    }\n",
    "    inner_model.load_state_dict(inner_state_dict)\n",
    "\n",
    "    inner_model = inner_model.to(torch.float16)\n",
    "    inner_model.eval()\n",
    "\n",
    "    inference_model = InferenceModel(inner_model)\n",
    "    \n",
    "    puzzle_emb_len = inner_model.puzzle_emb_len\n",
    "    seq_len_with_emb = 81 + puzzle_emb_len\n",
    "\n",
    "    dummy_inputs = torch.randint(1, 11, (batch_size, 81), dtype=torch.long, device=cfg.device)\n",
    "    dummy_puzzle_ids = torch.zeros(batch_size, dtype=torch.long, device=cfg.device)\n",
    "    \n",
    "    dummy_z_H_in = inner_model.H_init.unsqueeze(0).expand(batch_size, seq_len_with_emb, -1)\n",
    "    dummy_z_L_in = inner_model.L_init.unsqueeze(0).expand(batch_size, seq_len_with_emb, -1)\n",
    "    \n",
    "    assert dummy_z_H_in.dtype == torch.float16, f\"Expected float16 but got {dummy_z_H_in.dtype}\"\n",
    "    assert dummy_z_L_in.dtype == torch.float16, f\"Expected float16 but got {dummy_z_L_in.dtype}\"\n",
    "\n",
    "    print(f\"Exporting model to {ONNX_MODEL_PATH}...\")\n",
    "    torch.onnx.export(\n",
    "        inference_model,\n",
    "        (dummy_inputs, dummy_puzzle_ids, dummy_z_H_in, dummy_z_L_in),\n",
    "        ONNX_MODEL_PATH,\n",
    "        input_names=['inputs', 'puzzle_identifiers', 'z_H_in', 'z_L_in'],\n",
    "        output_names=['logits', 'z_H_out', 'z_L_out'],\n",
    "        opset_version=14,\n",
    "        do_constant_folding=True,\n",
    "        dynamic_axes={\n",
    "            'inputs': {0: 'batch_size'},\n",
    "            'puzzle_identifiers': {0: 'batch_size'},\n",
    "            'z_H_in': {0: 'batch_size'},\n",
    "            'z_L_in': {0: 'batch_size'},\n",
    "            'logits': {0: 'batch_size'},\n",
    "            'z_H_out': {0: 'batch_size'},\n",
    "            'z_L_out': {0: 'batch_size'},\n",
    "        }\n",
    "    )\n",
    "    print(\"Export complete.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    export_to_onnx()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
